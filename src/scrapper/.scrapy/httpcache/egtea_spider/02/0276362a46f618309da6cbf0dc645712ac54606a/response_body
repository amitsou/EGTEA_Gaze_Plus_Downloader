<!DOCTYPE html>
<html lang="en">
<head>
	<title>Georgia Tech Egocentric Activity Datasets</title>
	
	<meta charset="utf-8" />
	<meta name="viewport" content="width=device-width, minimum-scale=1.0, maximum-scale=1.0, user-scalable=no" />
	
	<!-- Stylesheets -->
	<link rel="stylesheet" type="text/css" href="stylesheets/base.css" />

	<link rel="stylesheet" type="text/css" href="stylesheets/media.queries.css" />
	<link rel="stylesheet" type="text/css" href="stylesheets/tipsy.css" />
	<link rel="stylesheet" type="text/css" href="javascripts/fancybox/jquery.fancybox-1.3.4.css" />
	<link rel="stylesheet" type="text/css" href="http://fonts.googleapis.com/css?family=Nothing+You+Could+Do|Quicksand:400,700,300">
	
	<!-- Javascripts -->
	<script type="text/javascript" src="javascripts/jquery-1.7.1.min.js"></script>
	<script type="text/javascript" src="javascripts/html5shiv.js"></script>
	<script type="text/javascript" src="javascripts/jquery.tipsy.js"></script>
	<script type="text/javascript" src="javascripts/fancybox/jquery.fancybox-1.3.4.pack.js"></script>
	<script type="text/javascript" src="javascripts/fancybox/jquery.easing-1.3.pack.js"></script>
	<script type="text/javascript" src="javascripts/jquery.touchSwipe.js"></script>
	<script type="text/javascript" src="javascripts/jquery.mobilemenu.js"></script>
	<script type="text/javascript" src="javascripts/jquery.infieldlabel.js"></script>
	<script type="text/javascript" src="javascripts/jquery.echoslider.js"></script>
	<script type="text/javascript" src="javascripts/fluidapp.js"></script>
	
	<!-- Favicons -->
	<link rel="shortcut icon" href="images/favicon.png" />
	<link rel="apple-touch-icon" href="images/apple-touch-icon.png">
	<link rel="apple-touch-icon" sizes="72x72" href="images/apple-touch-icon-72x72.png">
	<link rel="apple-touch-icon" sizes="114x114" href="images/apple-touch-icon-114x114.png">
	
</head>
<body>
	<!-- Start Wrapper -->
	<div id="page_wrapper">
		
	<!-- Start Header -->
	<header>
		<div class="container">
			<!-- Start Social Icons -->
			<aside>
				<ul class="social">
<!-- 					<li class="facebook"><a href="">Facebook</a></li>
					<li class="twitter"><a href="http://twitter.com/two2twelve">Twitter</a></li>
					<li class="email"><a href="" title="info@two2twelve.com">Email</a></li>
					<li class="rss"><a href="" title="App Updates">RSS</a></li> -->
					<!-- More Social Icons:
					<li class="dribbble"><a href="">Dribbble</a></li>
					<li class="google"><a href="">Google</a></li>
					<li class="flickr"><a href="">Flickr</a></li>
					-->
				</ul>
			</aside>
			<!-- End Social Icons -->
			
			<!-- Start Navigation -->
			<nav>
				<ul>
					<li><a href="#home">Home</a></li>
					<li><a href="#gtea">GTEA</a></li>
					<li><a href="#gtea_gaze">GTEA Gaze</a></li>
					<li><a href="#gtea_gaze_plus">GTEA Gaze+</a></li>
					<li><a href="#egtea_gaze_plus">EGTEA Gaze+</a></li>
					<li><a href="#contact">Contact</a></li>
				</ul>
				<span class="arrow"></span>
			</nav>
			<!-- End Navigation -->
		</div>
	</header>
	<!-- End Header -->
	
	<section class="container">
		
		<!-- Start App Info -->
		<div id="app_info">
			<!-- Start Logo -->
<!-- 			<a href="#home" class="logo">
				<img src="images/light-logo.png" alt="Fluid App" />
			</a> -->
			<!-- End Logo -->
			<span class="tagline">Georgia Tech Egocentric Activity Datasets</span>
			<p>
				Our repository of egocentric activity datasets! 
				<br> This page captures our effort on GTEA dataset series. 
				<br> Our latest and largest version is EGTEA Gaze+ dataset. 
				<br> We are working on further developing EGTEA Gaze+. Stay tuned!
			</p>
			
			<div class="buttons">
				<a class="large_button"></a>
				<a href="#gtea" class="large_button" id="apple">
					<em>Check now for</em> GTEA
				</a>
			</div>
			<div class="buttons">
				<a class="large_button"></a>
				<a href="#gtea_gaze" class="large_button" id="android">
					<em>Check now for</em> GTEA Gaze
				</a>
			</div>
			<div class="buttons">
				<a class="large_button"></a>
				<a href="#gtea_gaze_plus" class="large_button" id="windows">
					<em>Check now for</em> GTEA Gaze+
				</a>
			</div>

			<div class="buttons">
				<a class="large_button"></a>
				<a href="#egtea_gaze_plus" class="large_button" id="windows">
					<em>Check now for</em> EGTEA Gaze+
				</a>
			</div>

			<div class="price right_align"> <!-- Alignments options: right_align, left_align, centered -->
				<p>Recommended!</p>
			</div>
		</div>
		<!-- End App Info -->		
		
		<!-- Start Pages -->
		<div id="pages">
			<div class="top_shadow"></div>
			
			<!-- Start Home -->
			<div id="home" class="page">
				
				<div id="slider">

					<div class="slide">
						<div class="background white">
							<a href="#egtea_gaze_plus">
							<img src="images/slider/egtea_gp.jpg" alt="" />
							</a>
						</div>						
					</div>

					<div class="slide">
						<div class="background white">
							<a href="#gtea_gaze_plus">
							<img src="images/slider/gtea_gp.jpg" alt="" />
							</a>
						</div>						
					</div>

					<div class="slide">
						<div class="background white">
							<a href="#gtea_gaze">
							<img src="images/slider/gtea_gaze.jpg" alt="" />
							</a>
						</div>						
					</div>

					<div class="slide">
						<div class="background white">
							<a href="#gtea">
							<img src="images/slider/gtea.jpg" alt="" />
							</a>
						</div>						
					</div>
					
				</div>
			
			</div>
			<!-- End Home -->
			
			
							
			<!-- Start GTEA -->
			<div id="gtea" class="page">
				
				<h1>GTEA</h1>

				<h3>This dataset contains 7 types of daily activities, each performed by 4 different subjects. The camera is mounted on a cap worn by the subject.</h3>

				<br>
				<h4>We highly recommed replacing this dataset using EGTEA Gaze+!</h4>
				
				<div class="releases">
					<article class="release">
						<h2>Downloading Links</h2>
						<span class="date">Last updated, 2015</span>
						<ul>
							<a href="https://www.dropbox.com/s/xzdw0mloohtxjn5/gtea_videos.zip?dl=0">
								<li class="new"><span><b>Videos</b></span> Rectified videos at 15 fps</li>
							</a>
							<a href="https://www.dropbox.com/s/qlmhngmzwbqqp9q/gtea_png.zip?dl=0">
								<li class="fix"><span><b>Uncompressed PNG Files</b></span> Uncompressed frames</li>
							</a>
							<a href="https://www.dropbox.com/s/k2g06apgx1u8p17/hand2K_dataset.zip?dl=0">
								<li class="new"><span><b>Hand Masks</b></span> Annotated hand masks</li>
							</a>
							<a href="https://www.dropbox.com/s/yb6x4ez10bhx8sb/gtea_labels_71.zip?dl=0">
								<li class="fix"><span><b>Action Labels (new)</b></span> Annotated actions at 15 FPS (71 Classes)</li>
							</a>
							<a href="https://www.dropbox.com/s/ek0avfwmy41mxhj/gtea_labels_61.zip?dl=0">
								<li class="new"><span><b>Action Labels (old)</b></span> Annotated actions at 15 FPS (61 Classes)</li>
							</a>
						</ul>
					</article>
					
				</div>

				<h3>Please consider citing the following papers when using this dataset: </h3>
				<p> Alireza Fathi, Xiaofeng Ren, James M. Rehg, <br> <a href="http://amav.gatech.edu/sites/default/files/papers/cvpr2011.Fathi_.Ren_.Rehg_.printed.pdf">Learning to Recognize Objects in Egocentric Activities</a>, CVPR, 2011 <br> <br>
				Yin Li, Zhefan Ye, James M. Rehg. <br> <a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Li_Delving_Into_Egocentric_2015_CVPR_paper.pdf">Delving into Egocentric Actions</a>, CVPR 2015
				</p>
				
			</div>
			<!-- End GTEA -->


					
			<!-- Start GTEA Gaze -->
			<div id="gtea_gaze" class="page">
				
				<h1>GTEA Gaze</h1>

				<h3>This dataset is collected using Tobii eye-tracking glasses. It consists of 17 sequences, performed by 14 different subjects.</h3>

				<p>To record the sequences, we stuffed a table with various kinds of food, dishes and snacks. We asked each subject to wear the Tobii glasses and calibrated the gaze. Then we asked the subject to take a sit and make whatever food they feel like having. The beginning and ending time of the actions are annotated. Each action consists of a verb and a set of nouns. For example pouring milk into cup. In our experiments we extract images from video at 15 frames per second. Action annotations are based on frame numbers. The following sequences are used for <b>training: 1, 6, 7, 8, 10, 12, 13, 14, 16, 17, 18, 21, 22</b> and the following sequences are used for <b>testing: 2, 3, 5, 20</b>. <br> <br></p>

				<div class="press_mentions">
					<ul>
						<li>
							<div class="one_third">
								<a href="images/gaze.png" rel="screenshots" class="fancybox" title=""><img src="images/gaze.png" alt="" /></a>
							</div>

							<div class="details">
								<a href="https://www.dropbox.com/s/irfhpt2cxrguva3/gtea_gaze_dataset.zip?dl=0" class="button white">Download the dataset</a>
								<br> <br>
								<h4>We highly recommed replacing this dataset using EGTEA Gaze+!</h4>
							</div>
						</li>	
					</ul>
				</div>

				<h3>Please consider citing the following paper when using this dataset: </h3>
				<p> Alireza Fathi, Yin Li, James M. Rehg, <br> <a href="http://gtubicomp2015grad.pbworks.com/w/file/fetch/94746323/fathi-recognize-daily-actions-using-gaze2012.pdf">Learning to Recognize Daily Actions using Gaze</a>, ECCV, 2012 <br> <br>
				</p>
				
			</div>
			<!-- End GTEA Gaze -->


			<!-- Start GTEA Gaze Plus -->
			<div id="gtea_gaze_plus" class="page">
				
				<h1>GTEA Gaze+</h1>
				
				<h3>We collected this dataset using SMI eye-tracking glasses. We are more than half-way through the annotation, and here we have made the collected and annotated data available. The current version contains 37 videos with gaze tracking and action annotations. Audio files are also available upon request. </h3>

				<p> We collected this dataset at Georgia Tech's AwareHome. This dataset consists of seven meal-preparation activities, performed by 26 subjects. Subjects perform the activities based on the given cooking recipes (<a href="http://www.cbi.gatech.edu/fpv/Recipes.pdf">get the recipes here</a>). <br>
				Activities are: American Breakfast, Pizza, Snack, Greek Salad, Pasta Salad, Turkey Sandwich and Cheese Burger. SMI glasses record a HD video of subjects activities at 24 frames per second. They also record subject's gaze at 30 fps. <br>
				For each activity, we used ELAN to annotate its actions. An activity is a meal-preparation task such as making pizza, and an action is a short temporal segment such as putting sauce on the pizza crust, dicing the green peppers, washing the mushrooms, etc. </p>

				<br>
				<h4>We highly recommed replacing this dataset using EGTEA Gaze+!</h4>

				<div class="feature_list content_box">
					<div class="one_half">
						<h2 class="icon briefcase">American Breakfast</h2>
						<p>Video</p>
						<a href="https://www.dropbox.com/s/7vjk6zubmk7d5of/Ahmad_American.avi?dl=0" class="button black">P1</a>
						<a href="https://www.dropbox.com/s/sn1ddbhomi5i9qi/Alireza_American.avi?dl=0" class="button white">P2</a>
						<a href="https://www.dropbox.com/s/ep7bcw5bntlgpcj/Carlos_American.avi?dl=0" class="button gray">P3</a>
						<a href="https://www.dropbox.com/s/nujxdzf57auz01b/Rahul_American.avi?dl=0" class="button orange">P4</a>
						<a href="https://www.dropbox.com/s/o3m1tue03v5lrsj/Shaghayegh_American.avi?dl=0" class="button blue">P5</a>
						<a href="https://www.dropbox.com/s/i4ib0ctkxyzr5xr/Yin_American.avi?dl=0" class="button green">P6</a>

					</div>

					<div class="one_half column_last">
						<h2 class="icon briefcase">Pizza (Special)</h2>
						<p>Video</p>
						<a href="https://www.dropbox.com/s/5xy1c7g26di7gnz/Ahmad_Pizza.avi?dl=0" class="button black">P1</a>
						<a href="https://www.dropbox.com/s/q82zeypuv46ac7k/Alireza_Pizza.avi?dl=0" class="button white">P2</a>
						<a href="https://www.dropbox.com/s/w9dy6w3js68mvaa/Carlos_Pizza.avi?dl=0" class="button gray">P3</a>
						<a href="https://www.dropbox.com/s/la5jnr1n463ba99/Rahul_Pizza.avi?dl=0" class="button orange">P4</a>
						<a href="https://www.dropbox.com/s/ikif77zh8vy2ubl/Shaghayegh_Pizza.avi?dl=0" class="button blue">P5</a>
						<a href="https://www.dropbox.com/s/y8vqz41em7fyv6u/Yin_Pizza.avi?dl=0" class="button green">P6</a>

					</div>

					<div class="one_half">
						<h2 class="icon briefcase">Afternoon Snack</h2>
						<p>Video</p>
						<a href="https://www.dropbox.com/s/gomy3vpbl0hky2q/Ahmad_Snack.avi?dl=0" class="button black">P1</a>
						<a href="https://www.dropbox.com/s/vkz25aht1nlw536/Alireza_Snack.avi?dl=0" class="button white">P2</a>
						<a href="https://www.dropbox.com/s/svhblg97ut8v096/Carlos_Snack.avi?dl=0" class="button gray">P3</a>
						<a href="https://www.dropbox.com/s/fhm898zb94vtbv8/Rahul_Snack.avi?dl=0" class="button orange">P4</a>
						<a href="https://www.dropbox.com/s/pcokpqrdd0j6tvf/Shaghayegh_Snack.avi?dl=0" class="button blue">P5</a>
						<a href="https://www.dropbox.com/s/lcd7zxeuw0ufakj/Yin_Snack.avi?dl=0" class="button green">P6</a>

					</div>

					<div class="one_half column_last">
						<h2 class="icon briefcase">Greek Salad</h2>
						<p>Video</p>

						<a href="https://www.dropbox.com/s/jnuat3z1k6cn76i/Ahmad_Greek.avi?dl=0" class="button black">P1</a>
						<a href="https://www.dropbox.com/s/ddi8zbzuskyn1s6/Alireza_Greek.avi?dl=0" class="button white">P2</a>
						<a href="https://www.dropbox.com/s/0lf7vgs62v95iwf/Carlos_Greek.avi?dl=0" class="button gray">P3</a>
						<a href="https://www.dropbox.com/s/hjy7l1cubpyqjqs/Rahul_Greek.avi?dl=0" class="button orange">P4</a>
						<a href="https://www.dropbox.com/s/kwjhbe0it3q7sne/Yin_Greek.avi?dl=0" class="button green">P6</a>

					</div>

					<div class="one_half">
						<h2 class="icon briefcase">Pasta Salad</h2>
						<p>Video</p>
						<a href="https://www.dropbox.com/s/ivved8z2a5owyy6/Ahmad_Pasta.avi?dl=0" class="button black">P1</a>
						<a href="https://www.dropbox.com/s/rp3cpwsv2w9sk4g/Alireza_Pasta.avi?dl=0" class="button white">P2</a>
						<a href="https://www.dropbox.com/s/mbybqwilpsnbqmn/Carlos_Pasta.avi?dl=0" class="button gray">P3</a>
						<a href="https://www.dropbox.com/s/n5sj9jpfhta5fjj/Rahul_Pasta.avi?dl=0" class="button orange">P4</a>

					</div>

					<div class="one_half column_last">
						<h2 class="icon briefcase">Turkey Sandwich</h2>
						<p>Video</p>
						<a href="https://www.dropbox.com/s/6wmnvtxi3nxkfxe/Ahmad_Turkey.avi?dl=0" class="button black">P1</a>
						<a href="https://www.dropbox.com/s/13sdyf9gq7l9czz/Alireza_Turkey.avi?dl=0" class="button white">P2</a>
						<a href="https://www.dropbox.com/s/8oqaka0ferywscm/Carlos_Turkey.avi?dl=0" class="button gray">P3</a>
						<a href="https://www.dropbox.com/s/nquu92ksiuoi662/Rahul_Turkey.avi?dl=0" class="button orange">P4</a>
						<a href="https://www.dropbox.com/s/6p3akr39z4qdx20/Yin_Turkey.avi?dl=0" class="button green">P6</a>

					</div>

					<div class="one_half">
						<h2 class="icon briefcase">Cheese Burger</h2>
						<p>Video</p>
						<a href="https://www.dropbox.com/s/d5sam2j3uom8m9i/Ahmad_Burger.avi?dl=0" class="button black">P1</a>
						<a href="https://www.dropbox.com/s/5hpzyboaf7o4xuy/Alireza_Burger.avi?dl=0" class="button white">P2</a>
						<a href="https://www.dropbox.com/s/vjcm6x7w13ombkl/Carlos_Burger.avi?dl=0" class="button gray">P3</a>
						<a href="https://www.dropbox.com/s/j449adyxelv4o3t/Rahul_Burger.avi?dl=0" class="button orange">P4</a>
						<a href="https://www.dropbox.com/s/ux5rd6n5wk4w7xf/Yin_Burger.avi?dl=0" class="button green">P6</a>
					</div>

					<div class="one_half column_last">
						<h2 class="icon help">Gaze & Action Labels</h2>
						<h4>We have mistakenly put raw labels in Jan. 2016. Please re-download the cleaned action labels if you got the incorrect version.</h4>
						<a href="https://www.dropbox.com/s/7km96e6x8ms6uls/gaze.zip?dl=0" class="button black">Gaze</a>
						<a href="https://www.dropbox.com/s/ms1z1z8iqi997yp/GTEA_Gaze_Plus_labels_cleaned.zip?dl=0" class="button white">Labels</a>
						<a href="https://www.dropbox.com/s/k2g06apgx1u8p17/hand2K_dataset.zip?dl=0" class="button gray">Hand Masks</a>
						<br> <br>
						
					</div>
				</div>

			<br>

			<h3>Please consider citing the following papers when using this dataset: </h3>
			<p> Alireza Fathi, Yin Li, James M. Rehg, <br> <a href="http://gtubicomp2015grad.pbworks.com/w/file/fetch/94746323/fathi-recognize-daily-actions-using-gaze2012.pdf">Learning to Recognize Daily Actions using Gaze</a>, ECCV, 2012 <br> 
			Yin Li, Zhefan Ye, James M. Rehg. <br> <a href="http://www.cv-foundation.org/openaccess/content_cvpr_2015/papers/Li_Delving_Into_Egocentric_2015_CVPR_paper.pdf">Delving into Egocentric Actions</a>, CVPR 2015
			</p>
				
			</div>
			<!-- End GTEA Gaze Plus -->

			<div id="egtea_gaze_plus" class="page">
				
				<h1>Extended GTEA Gaze+</h1>

				<h3>EGTEA Gaze+ is our largest and most comprehensive dataset for FPV actions and gaze. It subsumes GTEA Gaze+ and comes with HD videos (1280x960), audios, gaze tracking data, frame-level action annotations, and pixel-level hand masks at sampled frames.</h3>

				<p>Specifically, EGTEA Gaze+ contains 28 hours (de-identified) of cooking activities from 86 unique sessions of 32 subjects. These videos comes with audios and gaze tracking (30Hz). We have further provided human annotations of actions (human-object interactions) and hand masks. </p>
				
				<br>
				<p>The action annotations include <strong>10325 instances of fine-grained actions</strong>, such as "Cut bell pepper" or "Pour condiment (from) condiment container into salad".</p>
				<br>
				<p>The hand annotations consist of <strong>15,176 hand masks</strong> from 13,847 frames from the videos.</p>
					


				<div class="feature_list content_box">
					<div class="one">
						<h2 class="icon briefcase">Documents / Raw Videos</h2>
						<a href="https://www.dropbox.com/s/i0qdxz484ufai5m/readme.md?dl=0" class="button green">Readme File</a>
						<a href="https://www.dropbox.com/s/w260trfnhdfcooh/Recipes.pdf?dl=0" class="button orange">Recipes</a>
						<a href="https://www.dropbox.com/s/uwwj6wb1j4rsm02/video_links.txt?dl=0" class="button gray">Links to raw videos (28G)</a>
					</div>

				</div>
				
				<div class="releases">
					<article class="release">
						<h2>Packaged Dataset</h2>
						<span class="date">Last updated, Nov. 2017</span>
						<ul>
							<a href="https://www.dropbox.com/s/udynz2u62wpdva6/video_clips.tar?dl=0">
								<li class="new"><span><b>Trimmed Action Clips</b></span>640x480 @ 24Fps (20G)</li>
							</a>
							<a href="https://www.dropbox.com/s/2aryvztw044w9ih/gaze_data.zip?dl=0">
								<li class="fix"><span><b>Gaze Data</b></span>Wearable Gaze Tracking @ 30Hz</li>
							</a>
							<a href="https://www.dropbox.com/s/ksro6eqa6v59859/action_annotation.zip?dl=0">
								<li class="new"><span><b>Action Annotations</b></span>Frame-Level Action Annotations (including train/test splits)</li>
							</a>
							<a href="https://www.dropbox.com/s/ysi2jv8qr9xvzli/hand14k.zip?dl=0">
								<li class="fix"><span><b>Hand Masks</b></span> Annotated hand masks (14K frames, 960x720)</li>
							</a>
						</ul>
					</article>
					
				</div>
                                <h3>Please consider citing the following papers when using this dataset: </h3>
                                <p> Yin Li, Miao Liu, James M. Rehg, <br> <a href="https://eccv2018.org/openaccess/content_ECCV_2018/papers/Yin_Li_In_the_Eye_ECCV_2018_paper.pdf">In the eye of beholder: Joint learning of gaze and actions in first person video</a>, ECCV, 2018 <br> <br>
                                </p>


				<h3>Special thanks to <a href="https://www.basicfinder.com/">BasicFinder</a> for providing the hand annotations</h3>
				
			</div>
			
			<!-- Start Start Contact -->
			<div id="contact" class="page">
				
				<h1>Contact</h1>
				
				<h3>For general questions or bug reports please contact <br><br> Miao Liu (mliu328@gatech.edu).</h3>
				
			</div>
			<!-- End Start Contact -->
			
			
			
			<div class="bottom_shadow"></div>
		</div>
		<!-- End Pages -->
		
		<div class="clear"></div>
	</section>
	
	<!-- Start Footer -->
	<footer class="container">
		<p>Georgia Tech &copy; 2017. All Rights Reserved.</p>
	</footer>
	<!-- End Footer -->
	
	</div>
	<!-- End Wrapper -->

</body>
</html>
